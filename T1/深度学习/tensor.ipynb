{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T21:01:24.471731Z",
     "end_time": "2023-04-14T21:01:26.019248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "cpu = tf.config.list_physical_devices(\"CPU\")\n",
    "tf.config.set_visible_devices(cpu)\n",
    "print(tf.config.list_logical_devices())\n",
    "\n",
    "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=32, inter_op_parallelism_threads=32)\n",
    "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T21:01:26.021239Z",
     "end_time": "2023-04-14T21:01:28.755436Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def getxy():\n",
    "    targetKey = '货量'\n",
    "    # 对场地进行编码\n",
    "\n",
    "    df = pd.read_excel('../../原始数据/附件1：物流网络历史货量数据.xlsx')\n",
    "    df['场地1'] = df['场地1'].str.replace('DC', '')\n",
    "    df['场地1'] = df['场地1'].astype('int64')\n",
    "    df['场地2'] = df['场地2'].str.replace('DC', '')\n",
    "    df['场地2'] = df['场地2'].astype('int64')\n",
    "\n",
    "    df['日期'] = pd.to_datetime(df['日期'])\n",
    "    df['日期'] = df['日期'] - df['日期'].min()\n",
    "    df['日期'] = df['日期'].apply(lambda x: x.days)\n",
    "    return df.drop(targetKey, axis=1), df[targetKey]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T21:01:28.758422Z",
     "end_time": "2023-04-14T21:01:28.786080Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重新训练模型\n",
      "Epoch 1/1000\n",
      "4985/5002 [============================>.] - ETA: 0s - loss: 199188896.0000 - mae: 6187.2578\n",
      "Epoch 1: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 9s 2ms/step - loss: 198942112.0000 - mae: 6185.0645 - val_loss: 154709312.0000 - val_mae: 7166.6152\n",
      "Epoch 2/1000\n",
      "4969/5002 [============================>.] - ETA: 0s - loss: 197882720.0000 - mae: 6199.9062\n",
      "Epoch 2: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 8s 2ms/step - loss: 197614400.0000 - mae: 6197.1489 - val_loss: 145932304.0000 - val_mae: 6451.2749\n",
      "Epoch 3/1000\n",
      "4971/5002 [============================>.] - ETA: 0s - loss: 196546688.0000 - mae: 6183.1123\n",
      "Epoch 3: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 8s 2ms/step - loss: 196198352.0000 - mae: 6180.8213 - val_loss: 140791344.0000 - val_mae: 6449.5635\n",
      "Epoch 4/1000\n",
      "4981/5002 [============================>.] - ETA: 0s - loss: 195422384.0000 - mae: 6163.2095\n",
      "Epoch 4: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 9s 2ms/step - loss: 195025184.0000 - mae: 6159.0972 - val_loss: 158418368.0000 - val_mae: 7542.1787\n",
      "Epoch 5/1000\n",
      "4998/5002 [============================>.] - ETA: 0s - loss: 192758480.0000 - mae: 6123.3076\n",
      "Epoch 5: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 8s 2ms/step - loss: 192674704.0000 - mae: 6122.7378 - val_loss: 142474128.0000 - val_mae: 6403.8872\n",
      "Epoch 6/1000\n",
      "4982/5002 [============================>.] - ETA: 0s - loss: 192696208.0000 - mae: 6137.4043\n",
      "Epoch 6: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 8s 2ms/step - loss: 192923024.0000 - mae: 6139.1733 - val_loss: 189363264.0000 - val_mae: 7675.5151\n",
      "Epoch 7/1000\n",
      "4988/5002 [============================>.] - ETA: 0s - loss: 190192880.0000 - mae: 6113.4766\n",
      "Epoch 7: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 8s 2ms/step - loss: 190330576.0000 - mae: 6117.7935 - val_loss: 218733632.0000 - val_mae: 9636.2373\n",
      "Epoch 8/1000\n",
      "4982/5002 [============================>.] - ETA: 0s - loss: 189063328.0000 - mae: 6105.3638\n",
      "Epoch 8: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 8s 2ms/step - loss: 189121152.0000 - mae: 6108.3345 - val_loss: 215600896.0000 - val_mae: 9605.8662\n",
      "Epoch 9/1000\n",
      "4991/5002 [============================>.] - ETA: 0s - loss: 188834320.0000 - mae: 6113.1040\n",
      "Epoch 9: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 8s 2ms/step - loss: 188718256.0000 - mae: 6110.9902 - val_loss: 135757760.0000 - val_mae: 6383.7095\n",
      "Epoch 10/1000\n",
      "4986/5002 [============================>.] - ETA: 0s - loss: 187018432.0000 - mae: 6110.1157\n",
      "Epoch 10: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 9s 2ms/step - loss: 186710224.0000 - mae: 6107.0977 - val_loss: 141637552.0000 - val_mae: 6233.5361\n",
      "Epoch 11/1000\n",
      "4996/5002 [============================>.] - ETA: 0s - loss: 186471568.0000 - mae: 6092.0630\n",
      "Epoch 11: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 8s 2ms/step - loss: 186536896.0000 - mae: 6093.2075 - val_loss: 155706384.0000 - val_mae: 8277.0156\n",
      "Epoch 12/1000\n",
      "4978/5002 [============================>.] - ETA: 0s - loss: 183699600.0000 - mae: 6050.9863\n",
      "Epoch 12: saving model to training-cp.ckpt\n",
      "INFO:tensorflow:Assets written to: training-cp.ckpt\\assets\n",
      "5002/5002 [==============================] - 9s 2ms/step - loss: 183996880.0000 - mae: 6056.0972 - val_loss: 178966928.0000 - val_mae: 7899.1230\n",
      "Epoch 13/1000\n",
      "2643/5002 [==============>...............] - ETA: 4s - loss: 192232512.0000 - mae: 6169.3970"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forceRetrain = True\n",
    "\n",
    "modelPath = 'model1.h5'\n",
    "\n",
    "X, Y = getxy()\n",
    "\n",
    "model = None\n",
    "shouldTrain = False\n",
    "if not os.path.exists(modelPath) or forceRetrain:\n",
    "    shouldTrain = True\n",
    "\n",
    "# 创建一个保存模型的回调函数\n",
    "checkpoint_path = \"training-cp.ckpt\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=False,\n",
    "                                                         verbose=1)\n",
    "\n",
    "if not shouldTrain:\n",
    "    print('加载模型')\n",
    "    # 加载模型\n",
    "    model = tf.keras.models.load_model(modelPath)\n",
    "else:\n",
    "    print('重新训练模型')\n",
    "\n",
    "    # 定义模型\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
    "        tf.keras.layers.Dense(256 * 2, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model = tf.keras.models.load_model(checkpoint_path)\n",
    "\n",
    "\n",
    "    # 定义自定义指标函数\n",
    "    def accuracy(y_true, y_pred):\n",
    "        threshold = 0.6  # 指定阈值\n",
    "        diff = tf.abs(y_true - y_pred)  # 计算预测值和真实值之差的绝对值\n",
    "        return tf.reduce_mean(tf.cast(diff <= threshold, tf.float32))  # 统计正确分类的样本数占总样本数的比例\n",
    "\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics='mae'\n",
    "                  )\n",
    "\n",
    "    # 训练模型\n",
    "    history = model.fit(X, Y, epochs=1000, validation_split=0.1, callbacks=[checkpoint_callback])\n",
    "\n",
    "    # 绘制学习曲线\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss, 'b-', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_acc, 'b-', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r-', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('Training and validation loss accuracy.svg')\n",
    "    plt.show()\n",
    "\n",
    "    # 可视化训练和测试误差\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    # plt.ylim([0, 10])\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.savefig('Model loss.svg')\n",
    "    plt.show()\n",
    "\n",
    "    # 保存模型\n",
    "    model.save(modelPath)\n",
    "\n",
    "# 预测并可视化结果\n",
    "y_pred = model.predict(X)\n",
    "plt.scatter(Y, y_pred)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "# plt.xlim([9e4, 1e5])\n",
    "# plt.ylim([9e4, 1e5])\n",
    "_ = plt.plot([-1e10, 1e10], [-1e10, 1e10])\n",
    "if shouldTrain:\n",
    "    plt.savefig('visualize result.svg')\n",
    "plt.show()\n",
    "\n",
    "print(f'r2_score: {r2_score(Y, y_pred)}')\n",
    "print(f'mse: {mean_squared_error(Y, y_pred)}')\n",
    "print(f'mae: {mean_absolute_error(Y, y_pred)}')\n",
    "print(f'mape: {mean_absolute_percentage_error(Y, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
