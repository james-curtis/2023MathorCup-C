{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-16T01:34:21.751349Z",
     "end_time": "2023-04-16T01:34:30.236031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         场地1   场地2         日期    货量\n0        DC1   DC8 2021-01-01     3\n1       DC10  DC12 2021-01-01   306\n2       DC10  DC13 2021-01-01     3\n3       DC10  DC14 2021-01-01  2613\n4       DC10  DC17 2021-01-01     2\n...      ...   ...        ...   ...\n765765   DC9  DC58 2022-12-31     1\n765766   DC9  DC62 2022-12-31     2\n765767   DC9  DC67 2022-12-31    44\n765768   DC9  DC79 2022-12-31     2\n765769   DC9   DC8 2022-12-31   107\n\n[765770 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>场地1</th>\n      <th>场地2</th>\n      <th>日期</th>\n      <th>货量</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DC1</td>\n      <td>DC8</td>\n      <td>2021-01-01</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DC10</td>\n      <td>DC12</td>\n      <td>2021-01-01</td>\n      <td>306</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DC10</td>\n      <td>DC13</td>\n      <td>2021-01-01</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DC10</td>\n      <td>DC14</td>\n      <td>2021-01-01</td>\n      <td>2613</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DC10</td>\n      <td>DC17</td>\n      <td>2021-01-01</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>765765</th>\n      <td>DC9</td>\n      <td>DC58</td>\n      <td>2022-12-31</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>765766</th>\n      <td>DC9</td>\n      <td>DC62</td>\n      <td>2022-12-31</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>765767</th>\n      <td>DC9</td>\n      <td>DC67</td>\n      <td>2022-12-31</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>765768</th>\n      <td>DC9</td>\n      <td>DC79</td>\n      <td>2022-12-31</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>765769</th>\n      <td>DC9</td>\n      <td>DC8</td>\n      <td>2022-12-31</td>\n      <td>107</td>\n    </tr>\n  </tbody>\n</table>\n<p>765770 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import *\n",
    "from statsmodels.graphics.tsaplots import *\n",
    "from catboost import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import *\n",
    "from sklearn.ensemble import *\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.metrics import *\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import shap\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import *\n",
    "import os\n",
    "\n",
    "# tf.compat.v1.disable_v2_behavior()\n",
    "forceCpu = False\n",
    "# 使用CPU\n",
    "if forceCpu:\n",
    "    cpu = tf.config.list_physical_devices(\"CPU\")\n",
    "    tf.config.set_visible_devices(cpu)\n",
    "    print(tf.config.list_logical_devices())\n",
    "\n",
    "# 动态显存\n",
    "if not forceCpu:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except:\n",
    "        print('Invalid device or cannot modify virtual devices once initialized')\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 黑体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决无法显示符号的问题\n",
    "palette = 'deep'\n",
    "sns.set(font='SimHei', font_scale=1.2, style='whitegrid', palette=palette)  # 解决Seaborn中文显示问题\n",
    "\n",
    "rawDataPiovt = pd.read_excel('../../../preprocess/均值填充-物流网络历史货量数据.xlsx')\n",
    "# 宽表转长表\n",
    "rawData = pd.melt(rawDataPiovt, id_vars=['场地1', '场地2'], var_name='日期', value_name='货量')\n",
    "rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def getxy():\n",
    "    targetKey = '货量'\n",
    "    # 对场地进行编码\n",
    "\n",
    "    df = rawData.copy()\n",
    "    # df = df[(df['场地1'] == 'DC14') & (df['场地2'] == 'DC10')].reset_index(drop=True)\n",
    "    df['场地1'] = df['场地1'].str.replace('DC', '')\n",
    "    df['场地1'] = df['场地1'].astype('int64')\n",
    "    df['场地2'] = df['场地2'].str.replace('DC', '')\n",
    "    df['场地2'] = df['场地2'].astype('int64')\n",
    "\n",
    "    df['日期'] = pd.to_datetime(df['日期'])\n",
    "    df['日期'] = df['日期'] - df['日期'].min()\n",
    "    df['日期'] = df['日期'].apply(lambda x: x.days)\n",
    "\n",
    "    df['货量'] = np.log(df['货量'])\n",
    "    return df.drop(targetKey, axis=1), df[targetKey], df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T01:22:10.829544Z",
     "end_time": "2023-04-16T01:22:10.838510Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "_, _, data = getxy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T01:22:11.265606Z",
     "end_time": "2023-04-16T01:22:13.368936Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset数量: 1049\n",
      "trainX.shape: (761574, 4, 4)\n",
      "trainY.shape: (761574,)\n"
     ]
    }
   ],
   "source": [
    "filterSize = 5\n",
    "\n",
    "\n",
    "# 将数据处理成模型可接受的形式\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        # a = dataset[i:(i + look_back), :-1]\n",
    "        # 自回归\n",
    "        a = dataset[i:(i + look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, -1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "# 按照时间排序\n",
    "data = data.sort_values('日期')\n",
    "\n",
    "# 将每条有向边转换成一个序列\n",
    "dataset = []\n",
    "for _, group in data.groupby(['场地1', '场地2']):\n",
    "    dataset.append(group.values)\n",
    "\n",
    "print(f'dataset数量: {len(dataset)}')\n",
    "\n",
    "# 将序列转换成模型可接受的形式\n",
    "'''\n",
    "`look_back`是一个超参数，它定义了我们在创建时间序列数据集时要考虑多少个时间步。\n",
    "具体地说，对于每条有向边的货量时间序列，我们将数据集中的每个样本定义为过去`look_back`个时间步的货量，目标是预测下一个时间步的货量。\n",
    "\n",
    "例如，\n",
    "如果`look_back`设置为1，我们将使用过去1天的货量数据来预测下一天的货量。\n",
    "如果`look_back`设置为3，我们将使用过去3天的货量数据来预测下一天的货量。\n",
    "通过调整`look_back`，我们可以控制模型应该考虑多少历史数据来进行预测。\n",
    "'''\n",
    "look_back = filterSize - 1\n",
    "trainX, trainY = [], []\n",
    "for i in range(len(dataset)):\n",
    "    train_x, train_y = create_dataset(dataset[i], look_back)\n",
    "    trainX.append(train_x)\n",
    "    trainY.append(train_y)\n",
    "\n",
    "trainX, trainY = np.concatenate(trainX), np.concatenate(trainY)\n",
    "\n",
    "print(f'trainX.shape: {trainX.shape}')\n",
    "print(f'trainY.shape: {trainY.shape}')\n",
    "# 和源数据177847相差3447"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T01:22:19.069051Z",
     "end_time": "2023-04-16T01:22:19.961096Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "modelPath = 'LSTM.1.h5'\n",
    "\n",
    "\n",
    "# 定义自定义指标函数\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res = tf.keras.backend.sum(tf.keras.backend.square(y_true - y_pred))\n",
    "    SS_tot = tf.keras.backend.sum(tf.keras.backend.square(y_true - tf.keras.backend.mean(y_true)))\n",
    "    return (1 - SS_res / (SS_tot + tf.keras.backend.epsilon()))\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(modelPath, custom_objects={'r_square': r_square})\n",
    "\n",
    "# 测试模型\n",
    "y_pred = model.predict(trainX, batch_size=5000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T01:26:18.463505Z",
     "end_time": "2023-04-16T01:26:19.440547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(761574, 1)\n",
      "数据量是否完整 True\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "# 数据量是否完整\n",
    "'''\n",
    "也就是每条线路前(filterSize - 1)不包含在预测值中\n",
    "'''\n",
    "print('数据量是否完整', y_pred.shape[0] + len(rawDataPiovt) * (filterSize - 1) == rawData.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T01:36:33.826057Z",
     "end_time": "2023-04-16T01:36:33.845054Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(761574, 4, 4)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T01:26:25.642617Z",
     "end_time": "2023-04-16T01:26:25.651590Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 8.        , 1.        , 1.09861229],\n       [1.        , 8.        , 2.        , 1.09861229],\n       [1.        , 8.        , 3.        , 1.09861229],\n       [1.        , 8.        , 4.        , 1.09861229]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T01:31:59.054970Z",
     "end_time": "2023-04-16T01:31:59.063941Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
